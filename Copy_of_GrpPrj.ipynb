{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FE2zXxFkkfo",
        "outputId": "54c2492d-3c0a-4f7d-e59f-984004528152"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "#We will make a basic CNN model to classify CIFAR-100#\n",
        "#We will use Keras from Tensorflow to build the model#\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "\n",
        "#show the tensorflow version\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmnZ1bRfkkfv",
        "outputId": "2296bdba-9218-49c6-e54a-cd19dca25291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "#Test if have GPU\n",
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IweHfQ7kkfx",
        "outputId": "11a35c3a-388c-414c-d6d6-938b0529803f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 6s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ]
        }
      ],
      "source": [
        "#load the CIFAR-100 dataset & split into train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "#Normalize pixel values from 1-255 to 0-1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "#show the shape of the dataset\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KoGEsouYkkfz"
      },
      "outputs": [],
      "source": [
        "#shuffle train & test data\n",
        "\n",
        "# # Assuming x_train and y_train are your data\n",
        "# indices = np.arange(x_train.shape[0])\n",
        "# np.random.shuffle(indices)\n",
        "\n",
        "# # Let's say we want to select 10000 random samples\n",
        "# x_train_subset = x_train[indices[:10000]]\n",
        "# y_train_subset = y_train[indices[:10000]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib-MfmILkkf0",
        "outputId": "915575dd-b2ad-4ec3-c6e0-82b841c9a78c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 1, 1, 512)         524800    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 1, 1, 512)         262656    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               25700     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1046980 (3.99 MB)\n",
            "Trainable params: 1046980 (3.99 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Build model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Block 1\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Block 2\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "# Block 2.5\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Block 3\n",
        "model.add(Conv2D(512, (4, 4), activation='relu', padding='valid'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(512, (1, 1), activation='relu', padding='same'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Block 4\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# Block 5\n",
        "model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAdE-8bPkkf2",
        "outputId": "a77ddb5a-96a9-41cf-ea8d-3623f54cf2b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 368s 234ms/step - loss: 4.3683 - accuracy: 0.0300 - val_loss: 3.9168 - val_accuracy: 0.0754\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 352s 225ms/step - loss: 3.7854 - accuracy: 0.1015 - val_loss: 3.5915 - val_accuracy: 0.1454\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 358s 229ms/step - loss: 3.4935 - accuracy: 0.1535 - val_loss: 3.3557 - val_accuracy: 0.1886\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 354s 227ms/step - loss: 3.2724 - accuracy: 0.1960 - val_loss: 3.1338 - val_accuracy: 0.2297\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 341s 218ms/step - loss: 3.0957 - accuracy: 0.2322 - val_loss: 3.0128 - val_accuracy: 0.2514\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 353s 226ms/step - loss: 2.9641 - accuracy: 0.2545 - val_loss: 2.9586 - val_accuracy: 0.2602\n",
            "Epoch 7/10\n",
            " 101/1563 [>.............................] - ETA: 5:10 - loss: 2.8596 - accuracy: 0.2639"
          ]
        }
      ],
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Train the model\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[tensorboard_callback])\n",
        "#save loss & validation loss every\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYy9YP44kkf3"
      },
      "outputs": [],
      "source": [
        "print(val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOnYsZEPkkf4"
      },
      "outputs": [],
      "source": [
        "#Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQz6-XDCkkf6"
      },
      "outputs": [],
      "source": [
        "#Plot the training history\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qd3H_1_kkf7"
      },
      "outputs": [],
      "source": [
        "#plot loss\n",
        "plt.plot(train_loss, label='train loss')\n",
        "plt.plot(val_loss, label = 'val loss')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "#legend\n",
        "plt.legend(loc='upper left')\n",
        "#show plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RatZm06Q6C9"
      },
      "outputs": [],
      "source": [
        "## CONFUSION MATRIX\n",
        "# Load both fine and coarse labels\n",
        "(x_train_fine, y_train_fine), (x_test_fine, y_test_fine) = cifar100.load_data(label_mode='fine')\n",
        "(x_train_coarse, y_train_coarse), (x_test_coarse, y_test_coarse) = cifar100.load_data(label_mode='coarse')\n",
        "\n",
        "# Establish a mapping from fine labels to coarse labels\n",
        "class_to_superclass = {}\n",
        "for fine, coarse in zip(y_train_fine.flatten(), y_train_coarse.flatten()):\n",
        "    if fine not in class_to_superclass:\n",
        "        class_to_superclass[fine] = coarse\n",
        "\n",
        "# Optional: Check the mapping (for understanding/debugging)\n",
        "print(\"Sample of class to superclass mapping:\", {k: class_to_superclass[k] for k in list(class_to_superclass)[:5]})\n",
        "\n",
        "# Predict the classes using the trained model\n",
        "y_pred = model.predict(x_test_fine)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_pred_super = np.vectorize(class_to_superclass.get)(y_pred_classes)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute the confusion matrix for superclasses\n",
        "cm_super = confusion_matrix(y_test_coarse, y_pred_super)\n",
        "\n",
        "# Display the confusion matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_super)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix for Superclasses')\n",
        "plt.xlabel('Predicted Superclass')\n",
        "plt.ylabel('True Superclass')\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
